{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color='navy'>Grafovi</font><h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>U ovom poglavlju uvodimo osnovne elemente teorije grafova, koji čine osnovu na kojoj se zasniva oblast <b>Grafovskih neuronskih mreža sa mehanizmom pažnje (GAT)</b>. Zbog velikog spektra primena, kao i izuzetno jednostavne definicije i osnovnih svojstava, grafovi su našli i veliku primenu u mnogim matematičkim oblastima poput kombinatorike, operacionih istraživanja, linearne algebre, računarstva itd.</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color='navy'>Osnovni pojmovi teorije grafova</font><h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definicija 1:** Graf $G$ predstavlja uređeni par $(V,E)$. Elementi skupa $V$ se nazivaju *čvorovi* (eng. *vertex*), a elementi skupa $E$ *grane* (eng. *edge*) grafa $G$ gde je $E \\subseteq V \\times V$. Dva čvora $u,v$ su **susedni** ako su spojeni granom $e=\\{u,v\\}$. Za čvor $u$ i granu $e$ tada kažemo da su **incidentni**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafovi se prema usmerenosti mogu podeliti na:\n",
    "- <b>Neusmerene grafove</b>, za koje važi da nemaju svojstvo usmerenja između čvorova sa kojima su incidenti, zbog čega grane smatramo skupovima čvorova i pišemo, npr. $e=\\{u,v\\}$.\n",
    "- <b>Usmerene grafove</b>, za koje važi da grane imaju svojstvo usmerenja od jednog čvora, koji se naziva *izlazni čvor* ka drugom čvoru koji se naziva *ulazni čvor*. U tom slučaju, grane grafa ne smatramo skupovima već uređenim parovima i pišemo, npr, $e=(u,v), e=(v,u)$, u zavisnosti od smera usmerenja grane e incidentne sa čvorovima $u,v$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafovi se grafički predstavljaju na sledeći način:\n",
    "- Svaki čvor se predstavlja jednim krugom\n",
    "- Svaka grana se predstavlja linijom koja povezuje čvorove sa kojima je incidentna. Ako je graf usmeren, onda se koristi strelica u smeru od izlaznog čvora ka ulaznom čvoru incidentinim sa tom granom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na slici su dati primeri 2 grafa:\n",
    "- Graf $G_1=(V_1, E_1)$, gde je $V_1=\\{a, b, c\\}, E_1=\\{ (a, b), (b, c), (c, b), (c, a)\\}$, primer je usmerenog grafa.\n",
    "- Graf $G_2=(V_2, E_2)$, gde je $V_2=\\{a, b, c, d\\}, E_2=\\{ (a, b), (c, b), (a, d), (c, d)\\}$, primer je neusmerenog grafa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './da.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m rcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure.figsize\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m ,\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m----> 9\u001b[0m img_A \u001b[38;5;241m=\u001b[39m \u001b[43mmpimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./da.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m img_B \u001b[38;5;241m=\u001b[39m mpimg\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./ne.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\mlmatf-gnn\\lib\\site-packages\\matplotlib\\image.py:1496\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   1494\u001b[0m                 response \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(response\u001b[38;5;241m.\u001b[39mread())\n\u001b[0;32m   1495\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m imread(response, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mext)\n\u001b[1;32m-> 1496\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimg_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[0;32m   1497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[0;32m   1498\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, PIL\u001b[38;5;241m.\u001b[39mPngImagePlugin\u001b[38;5;241m.\u001b[39mPngImageFile) \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m   1499\u001b[0m             pil_to_array(image))\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\mlmatf-gnn\\lib\\site-packages\\PIL\\ImageFile.py:104\u001b[0m, in \u001b[0;36mImageFile.__init__\u001b[1;34m(self, fp, filename)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodermaxblock \u001b[38;5;241m=\u001b[39m MAXBLOCK\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isPath(fp):\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;66;03m# filename\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './da.png'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rcParams\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "rcParams['figure.figsize'] = 15 ,10\n",
    "\n",
    "img_A = mpimg.imread('./da.png')\n",
    "img_B = mpimg.imread('./ne.png')\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(img_A)\n",
    "ax[1].imshow(img_B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote> Grafovi su apstraktni pojmovi koji se mogu susresti u svakodnevnom životu i značajni su jer se veliki broj koncepata može modelovati njima.\n",
    "Ako posmatramo neku geografsku mapu sa mnoštvom gradova koji su povezani nekim putevima-dobijamo jedan graf. Strukturna formula nekog molekula ili jedinjenja predstavlja takođe jedan graf . Društvene mreže se prirodno mogu opisati grafom u kojem se svakom korisniku društvene mreže dodeljuje čvor, a grana između dva čvora postoji ukoliko su korisnici 'prijatelji' (facebook, neusmeren graf), ili ako jedan korisnik 'prati' drugog korisnika (Twitter, usmeren graf).</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color='navy'>Računarska reprezentacija grafova</font><h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>S obzirom da postoji veliki broj podataka u problemima koji se modeluju grafovima, postavlja se pitanje izbora njihove reprezentacije u računarima. Najčešće se za predstavljanje grafova koristi matrična reprezentacija.</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definicija 2:** <b>Matrica susedstva</b> $A$ grafa $G=(V,E)$, dimenzija $\\vert V \\vert \\times \\vert V \\vert$, definiše se na sledeći način: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A_{ij}=\n",
    "\\begin{cases}\n",
    "1 & (i, j) \\in E \\\\\n",
    "0 & (i, j) \\notin E \\\\\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ako je graf neusmeren, onda je matrica A simetrična, pa nije potrebno čuvati sve elemente matrice, već samo njenu gornje-trougaonu reprezentaciju. Čak i ako grafovi nisu neusmereni, oni su često *retki*, odnosno, nemaju veliki broj grana, pa se matrice susedstava čuvaju u specifičnim strukturama podataka koje se nazivaju retke matrice. One imaju dve značajne pogodnosti za korišćenje u odnosu na ne-retke matrice.\n",
    "- Ne-retke matrice zahtevaju memorijski prostor asimptotske složenosti $O(\\vert V \\vert^2)$, dok retke matrice zahtevaju memorijski prostor asimptotske složenosti $O(\\vert E \\vert)$.\n",
    "- Operacije koje se izvršavaju nad retkim matricama su efikasnije u odnosu na operacije nad uobičajenim reprezentacijama matricama. U algoritmima mašinskog učenja, značajna operacija je množenje matrica i vektora. Složenost je ista kao i u prethodnom primeru, i to značajno ubrzava proces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color='navy'>Grafovske neuronske mreže</font><h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Konvolutivne neuronske mreže</b> (CNNs) su uspešno rešavale probleme klasifikacije slika ili semantičke segmentacije, gde podaci imaju strukturu nalik mreži. Međutim mnogi zanimljivi problemi uključuju podatke koji se ne mogu predstaviti u mrežnoj strukturi i koji se zasnivaju na neregularnom domenu. Ovo je slučaj sa društvenim mrežama, telekomunikacionim mrežama, moždanim konektorima itd. Takvi podaci se obično mogu predstaviti u obliku <b>grafa</b> (kao što je opisano u prethodnim primerima)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><b>Grafovske neuronske mreže sa mehanizmom pažnje (GAT)</b> su novije neuronske mreže koje rade sa podacima koji su predstavljeni i strukturirani grafom, koje koriste maskirane slojeve mehanizma pažnje kako bi unapredili i poboljšali nedostatke starijih algoritama koji su bili bazirani na grafovskim konvolutivnim mrežama. Slaganjem slojeva u kojima čvorovima može da se pristupi preko karakteristika njegovih susednih čvorova, omogućavamo implicitno navođenje različitih težina za različite čvorove u susedstvu, bez potrebe za bilo kakvom zahtevnom matričnom operacijom (kao što je npr. inverzija). Na ovaj način je obuhvaćeno nekoliko ključnih izazova neuronskih mreža i činimo model jednako primenljivim i na induktivne i transduktivne probleme. Naši GAT modeli su dali rezultate nad bazom podataka Cora.</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('./gat slika1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pravilo propagacije kod grafovskih neuronskih mreža je definisano na sledeći način:\n",
    "\n",
    "$$\n",
    "H^{(k+1)} = \\sigma \\bigl(\\hat{A}H^{(k)}W^{(k)}\\bigr)\n",
    "$$\n",
    "\n",
    "gde je sa $k$ numerisan sloj mreže, $\\sigma$ je aktivaciona funkcija, $H^{(0)}=X$, tj. ulazna matrica prediktora, $\\hat{A} = \\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}$ simetrična normalizovana matrica susedstva grafa $G$ sa dodatim petljama za svaki čvor, gde je $\\tilde{A} = A+I_N$ ($N$ je broj čvorova, $A$ je matrica susedstva) i $\\tilde{D}_{ii} = \\sum_{j}^{}\\tilde{A}_{ij}$, $W^{(k)}$ je matrica parametara modela za sloj $k$.\n",
    "Matrica susedstva se normalizuje da bi proces optimizacije kroz duboku neuronsku mrežu bio stabilniji. Dakle, arhitektura je slična kao kod potpuno povezanih neuronskih mreža, samo što je dodata i matrica susedstva čvorova grafa.\n",
    "<br/> Primer grafovske neuronske mreže sa dva sloja je:\n",
    "\n",
    "$$\n",
    "f(X,A) = \\text{softmax}\\bigl(\\hat{A} \\hspace{1.2mm} \\text{LeakyReLU}(\\hat{A}XW^{(0)})W^{(1)}\\bigr)\n",
    "$$\n",
    "\n",
    "Gde je $W^{(0)} \\in \\mathbb{R}^{d \\times h^{(0)}}$ matrica parametara za sloj koji spaja ulazne podatke dimenzije $d$ i podatke prvog skrivenog sloja dimenzije $h^{(0)}$, a $W^{(1)} \\in \\mathbb{R}^{h^{(0)} \\times h^{(1)}}$ je matrica parametara za sloj koji spaja skrivene podatke i izlazne podatke.\n",
    "Na izlazu iz ulaznog sloja primenjuje se aktivaciona funkcija LeakyReLU, a na izlazu iz skrivenog sloja primenjuje se aktivaciona funkcija softmax. Ove dve funkcije su definisane sledećim formulama:\n",
    "\n",
    "$$\n",
    "\\text{LeakyReLU(x)} = \\max(\\alpha x, x), \\alpha >0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{softmax}(x_j) = \\frac{\\exp(x_j)}{\\sum_{i}^{}\\exp(x_i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><font color='navy'>Mehanizam pažnje nad grafom</font><h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ulazni podaci za sloj sa mehanizmom pažnje čine skup $h=\\{h_1,h_2,...,h_N\\}$, $h_i \\in \\mathbb{R}^F$, gde je $N$ broj čvorova grafa, a $F$ je dimenzija atributa za svaki čvor. Izlazni podaci ovog sloja čine novi skup atributa $\\{h_1',h_2',...,h_N'\\}$, $h_i' \\in \\mathbb{R}^{F'}$, potencijalno različite dimenzije $F'$.\n",
    "Izlazni podaci se računaju sledećom formulom:\n",
    "\n",
    "$$\n",
    "h_i' = \\sigma\\biggl(\\sum_{j \\in N_i}^{} \\alpha_{ij}Wh_j\\biggr)\n",
    "$$\n",
    "\n",
    "gde je $\\sigma$ aktivaciona funkcija, $N_i$ skup suseda $i$-tog čvora, $W \\in \\mathbb{R}^{F'\\times F} $ matrica parametara koja je ista za svaki čvor, $\\alpha_{ij}$ normalizovani koeficijenti pažnje (eng. *normalised attention coefficients*).\n",
    "Normalizovani koeficijent pažnje $\\alpha_{ij}$ nam govori o važnosti atributa $j$-tog čvora za $i$-ti čvor. Postupak za njegovo izračunavanje dat je sledećom formulom:\n",
    "\n",
    "$$\n",
    "\\alpha_{ij} = \\frac{\\exp(e_{ij})}{\\sum_{k \\in N_i}^{}\\exp(e_{ik})}\n",
    "$$\n",
    "\n",
    "gde su $e_{ik}$ koeficijenti pažnje i oni se računaju sledećom formulom:\n",
    "\n",
    "$$\n",
    "e_{ij} = a(Wh_i, Wh_j)\n",
    "$$\n",
    "\n",
    "gde je $a: \\mathbb{R}^{F'} \\times \\mathbb{R}^{F'} \\rightarrow \\mathbb{R}$ funkcija koja se naziva mehanizmom pažnje (eng. *attention mechanism*).\n",
    "U našem zadatku će mehanizam pažnje biti jednoslojna neuronska mreža parametrizovana vektorom $\\vec{a} \\in \\mathbb{R}^{2F'}$, na koju se primenjuje aktivaciona funkcija LeakyReLU.\n",
    "\n",
    "\n",
    "Dakle, formula za izračunavanje normalizovanih koeficijenata pažnje je data sa:\n",
    "\n",
    "$$\n",
    "\\alpha_{ij} = \\frac{\\exp\\bigl(\\text{LeakyReLU}\\bigl(\\vec{a}^T\\big[Wh_i \\big|\\big| Wh_j\\big]\\bigr)\\bigr)}{\\sum_{k \\in N_i}^{}\\exp\\bigl(\\text{LeakyReLU}\\bigl(\\vec{a}^T\\big[Wh_i \\big|\\big| Wh_j\\big]\\bigr)\\bigr)}\n",
    "$$\n",
    "\n",
    "gde je $\\parallel$ operacija nadovezivanja, a $^{T}$ operacija transponovanja.\n",
    "\n",
    "Radi stabilizacije procesa učenja pažnje, koristi se mehanizam višestruke pažnje (eng. *multi-head attention*), u kojem koristimo $K$ nezavisnih mehanizama pažnje i pomoću svakog dobijamo izlazne atribute. Nakon toga se izlazni atributi nadovezuju i dobijamo sledeću reprezentaciju izlaznih atributa:\n",
    "\n",
    "$$\n",
    "h_i' = \\Bigg|\\Bigg| \\sigma\\biggl(\\sum_{j \\in N_i}^{}\\alpha_{ij}^kW_kh_j\\biggr)\n",
    "$$\n",
    "\n",
    "gde je $\\parallel$ operacija nadovezivanja atributa za $k$ od 1 do $K$, $\\alpha_{ij}^k$ su normalizovani koeficijenti pažnje izračunati pomoću $k$-tog mehanizma pažnje, $W_k$ je odgovarajuća matrica parametara. Primetimo da će u ovom slučaju dimenzija izlaznog čvora biti $KF'$. Posebno, u poslednjem sloju neuronske mreže umesto nadovezivanja vrši se uprosečavanje, kako bi se dobio izlaz odgovarajuće dimenzije, nakon čega se vrši konačna nelinearna transformacija (npr. softmax u slučaju klasifikacije). Dakle, izlazni atributi poslednjeg sloja su dati formulom:\n",
    "\n",
    "$$\n",
    "h_i' = \\sigma\\biggl(\\frac{1}{K}\\sum_{k=1}^{K}\\sum_{j \\in N_i}^{}\\alpha_{ij}^kW_kh_j\\biggr)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
